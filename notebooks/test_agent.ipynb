{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302414a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π (–∑–∞–ø—É—Å—Ç–∏ –æ–¥–∏–Ω —Ä–∞–∑)\n",
    "!pip install rapidfuzz arxiv httpx tenacity pydantic -q\n",
    "\n",
    "print(\"‚úÖ –í—Å—ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c8629",
   "metadata": {},
   "source": [
    "# üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è Paper Survey Agent\n",
    "\n",
    "–¶–µ–π notebook —Ç–µ—Å—Ç—É—î —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å –ø–æ—à—É–∫—É —Ç–∞ —Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è –Ω–∞—É–∫–æ–≤–∏—Ö —Å—Ç–∞—Ç–µ–π.\n",
    "\n",
    "## 0. –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π\n",
    "\n",
    "–°–ø–æ—á–∞—Ç–∫—É –≤—Å—Ç–∞–Ω–æ–≤–∏–º–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –ø–∞–∫–µ—Ç–∏:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc8600",
   "metadata": {},
   "source": [
    "## 1. –Ü–º–ø–æ—Ä—Ç–∏\n",
    "\n",
    "–Ü–º–ø–æ—Ä—Ç—É—î–º–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –º–æ–¥—É–ª—ñ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3213c49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥—É–ª—ñ —É—Å–ø—ñ—à–Ω–æ —ñ–º–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# –î–æ–¥–∞—î–º–æ src –¥–æ path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from paper_survey_agent.tools import retrieve_papers, rank_and_deduplicate\n",
    "from paper_survey_agent.models.paper import Paper\n",
    "\n",
    "print(\"‚úÖ –ú–æ–¥—É–ª—ñ —É—Å–ø—ñ—à–Ω–æ —ñ–º–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195e22e",
   "metadata": {},
   "source": [
    "## 2. –¢–µ—Å—Ç 1: –ü–æ—à—É–∫ —Å—Ç–∞—Ç–µ–π –ø—Ä–æ Transformers\n",
    "\n",
    "–®—É–∫–∞—î–º–æ —Å—Ç–∞—Ç—Ç—ñ –ø—Ä–æ transformer models –∑ arXiv —Ç–∞ Semantic Scholar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498f8680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –®—É–∫–∞—î–º–æ —Å—Ç–∞—Ç—Ç—ñ –∑–∞ –∑–∞–ø–∏—Ç–æ–º: 'transformer models'...\n",
      "\n",
      "\n",
      "‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ 20 —Å—Ç–∞—Ç–µ–π\n",
      "\n",
      "‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ 20 —Å—Ç–∞—Ç–µ–π\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ—à—É–∫ —Å—Ç–∞—Ç–µ–π\n",
    "query = \"transformer models\"\n",
    "print(f\"üîç –®—É–∫–∞—î–º–æ —Å—Ç–∞—Ç—Ç—ñ –∑–∞ –∑–∞–ø–∏—Ç–æ–º: '{query}'...\\n\")\n",
    "\n",
    "papers = await retrieve_papers(\n",
    "    query=query,\n",
    "    sources=[\"arxiv\", \"semantic_scholar\"],\n",
    "    max_results_per_source=10\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(papers)} —Å—Ç–∞—Ç–µ–π\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a30342",
   "metadata": {},
   "source": [
    "### –ü–µ—Ä–µ–≥–ª—è–¥ –ø–µ—Ä—à–∏—Ö –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a416b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö –ü–µ—Ä—à—ñ 5 –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π:\n",
      "\n",
      "1. PyramidTNT: Improved Transformer-in-Transformer Baselines with Pyramid Architecture\n",
      "   üìÖ –î–∞—Ç–∞: 2022-01-04\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Kai Han, Jianyuan Guo, Yehui Tang...\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: arXiv\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: N/A\n",
      "   üîó URL: http://arxiv.org/abs/2201.00978v1\n",
      "\n",
      "2. Glance-and-Gaze Vision Transformer\n",
      "   üìÖ –î–∞—Ç–∞: 2021-06-04\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Qihang Yu, Yingda Xia, Yutong Bai...\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: arXiv\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: N/A\n",
      "   üîó URL: http://arxiv.org/abs/2106.02277v1\n",
      "\n",
      "3. Learning to Cluster Faces via Transformer\n",
      "   üìÖ –î–∞—Ç–∞: 2021-04-23\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Jinxing Ye, Xioajiang Peng, Baigui Sun...\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: arXiv\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: N/A\n",
      "   üîó URL: http://arxiv.org/abs/2104.11502v1\n",
      "\n",
      "4. Advancing Plain Vision Transformer Towards Remote Sensing Foundation Model\n",
      "   üìÖ –î–∞—Ç–∞: 2022-08-08\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Di Wang, Qiming Zhang, Yufei Xu...\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: arXiv\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: N/A\n",
      "   üîó URL: http://arxiv.org/abs/2208.03987v4\n",
      "\n",
      "5. MLP Can Be A Good Transformer Learner\n",
      "   üìÖ –î–∞—Ç–∞: 2024-04-08\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Sihao Lin, Pumeng Lyu, Dongrui Liu...\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: arXiv\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: N/A\n",
      "   üîó URL: http://arxiv.org/abs/2404.05657v1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üìö –ü–µ—Ä—à—ñ 5 –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π:\\n\")\n",
    "\n",
    "for i, paper in enumerate(papers[:5], 1):\n",
    "    print(f\"{i}. {paper.title}\")\n",
    "    print(f\"   üìÖ –î–∞—Ç–∞: {paper.published_date}\")\n",
    "    print(f\"   üë• –ê–≤—Ç–æ—Ä–∏: {', '.join(paper.authors[:3])}{'...' if len(paper.authors) > 3 else ''}\")\n",
    "    print(f\"   üìä –î–∂–µ—Ä–µ–ª–æ: {paper.source}\")\n",
    "    print(f\"   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: {paper.citations_count if paper.citations_count else 'N/A'}\")\n",
    "    print(f\"   üîó URL: {paper.url}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c310e5",
   "metadata": {},
   "source": [
    "## 3. –†–∞–Ω–∂—É–≤–∞–Ω–Ω—è —Ç–∞ –¥–µ–¥—É–ø–ª—ñ–∫–∞—Ü—ñ—è\n",
    "\n",
    "–¢–µ–ø–µ—Ä –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä—É—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏ —Ç–∞ –≤—ñ–¥—Ä–∞–Ω–∂—É—î–º–æ —Å—Ç–∞—Ç—Ç—ñ –∑–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a333db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ –†–∞–Ω–∂—É—î–º–æ 20 —Å—Ç–∞—Ç–µ–π...\n",
      "\n",
      "\n",
      "‚úÖ –¢–æ–ø-10 –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à–∏—Ö —Å—Ç–∞—Ç–µ–π (–ø—ñ—Å–ª—è –¥–µ–¥—É–ø–ª—ñ–∫–∞—Ü—ñ—ó)\n"
     ]
    }
   ],
   "source": [
    "print(f\"üîÑ –†–∞–Ω–∂—É—î–º–æ {len(papers)} —Å—Ç–∞—Ç–µ–π...\\n\")\n",
    "\n",
    "ranked_papers = rank_and_deduplicate(\n",
    "    papers=papers,\n",
    "    topic=query,\n",
    "    top_k=10,\n",
    "    fuzzy_threshold=85\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ –¢–æ–ø-{len(ranked_papers)} –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à–∏—Ö —Å—Ç–∞—Ç–µ–π (–ø—ñ—Å–ª—è –¥–µ–¥—É–ø–ª—ñ–∫–∞—Ü—ñ—ó)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d094eaf",
   "metadata": {},
   "source": [
    "### –¢–æ–ø-10 —Å—Ç–∞—Ç–µ–π:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de4a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ –¢–æ–ø-10 –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à–∏—Ö —Å—Ç–∞—Ç–µ–π:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "1. GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: J. Ainslie, J. Lee-Thorp...\n",
      "   üìÖ –î–∞—Ç–∞: 2023-05-22\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 1055\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "   üîó URL: https://www.semanticscholar.org/paper/5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200\n",
      "   üìÑ PDF: http://arxiv.org/pdf/2305.13245\n",
      "\n",
      "   üìù Abstract: Multi-query attention (MQA), which only uses a single key-value head, drastically speeds up decoder inference. However, MQA can lead to quality degradation, and moreover it may not be desirable to tra...\n",
      "   ----------------------------------------------------------------------------\n",
      "\n",
      "2. CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Zhuoyi Yang, Jiayan Teng...\n",
      "   üìÖ –î–∞—Ç–∞: 2024-08-12\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 1198\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "   üîó URL: https://www.semanticscholar.org/paper/7b248d78573ccf0dca6aa2cec2743d3eccaa9d1a\n",
      "\n",
      "   üìù Abstract: We present CogVideoX, a large-scale text-to-video generation model based on diffusion transformer, which can generate 10-second continuous videos aligned with text prompt, with a frame rate of 16 fps ...\n",
      "   ----------------------------------------------------------------------------\n",
      "\n",
      "3. OPT: Open Pre-trained Transformer Language Models\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Susan Zhang, Stephen Roller...\n",
      "   üìÖ –î–∞—Ç–∞: 2022-05-02\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 4302\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "   üîó URL: https://www.semanticscholar.org/paper/13a0d8bb38f739990c8cd65a44061c6534f17221\n",
      "\n",
      "   üìù Abstract: Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these mode...\n",
      "   ----------------------------------------------------------------------------\n",
      "\n",
      "4. DeepSpeed- Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Reza Yazdani Aminabadi, Samyam Rajbhandari...\n",
      "   üìÖ –î–∞—Ç–∞: 2022-06-30\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 482\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "   üîó URL: https://www.semanticscholar.org/paper/c022f75b00d795c6297d6a9ea948856ea4d365a1\n",
      "   üìÑ PDF: https://arxiv.org/pdf/2207.00032\n",
      "\n",
      "   üìù Abstract: The landscape of transformer model inference is increasingly diverse in model size, model characteristics, latency and throughput requirements, hardware requirements, etc. With such diversity, designi...\n",
      "   ----------------------------------------------------------------------------\n",
      "\n",
      "5. Transformer models in biomedicine\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: S. Madan, Manuel Lentzen...\n",
      "   üìÖ –î–∞—Ç–∞: 2024-07-29\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 51\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "   üîó URL: https://www.semanticscholar.org/paper/5ff90e0747199dc8578e5643028b2c4d4750188c\n",
      "   üìÑ PDF: https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-024-02600-5\n",
      "\n",
      "   üìù Abstract: Deep neural networks (DNN) have fundamentally revolutionized the artificial intelligence (AI) field. The transformer model is a type of DNN that was originally used for the natural language processing...\n",
      "   ----------------------------------------------------------------------------\n",
      "\n",
      "6. Transformer Models in Healthcare: A Survey and Thematic Analysis of Potentials, Shortcomings and Risks\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Kerstin Denecke, R. May...\n",
      "   üìÖ –î–∞—Ç–∞: 2024-02-17\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 44\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "   üîó URL: https://www.semanticscholar.org/paper/815bf0a659f3363fbf8f51632b58f29bcb699491\n",
      "\n",
      "   üìù Abstract: Large Language Models (LLMs) such as General Pretrained Transformer (GPT) and Bidirectional Encoder Representations from Transformers (BERT), which use transformer model architectures, have significan...\n",
      "   ----------------------------------------------------------------------------\n",
      "\n",
      "7. Integrating prior knowledge to build transformer models\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Pei-pei Jiang, Takashi Obi...\n",
      "   üìÖ –î–∞—Ç–∞: 2024-01-02\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 31\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "   üîó URL: https://www.semanticscholar.org/paper/f09fb94199290b4638a91750540bbbed4e4420b1\n",
      "   üìÑ PDF: https://link.springer.com/content/pdf/10.1007/s41870-023-01635-7.pdf\n",
      "\n",
      "   üìù Abstract: The big Artificial General Intelligence models inspire hot topics currently. The black box problems of Artificial Intelligence (AI) models still exist and need to be solved urgently, especially in the...\n",
      "   ----------------------------------------------------------------------------\n",
      "\n",
      "8. Comprehensive review and comparative analysis of transformer models in sentiment analysis\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Hadis Bashiri, Hassan Naderi\n",
      "   üìÖ –î–∞—Ç–∞: 2024-09-06\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 35\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "   üîó URL: https://www.semanticscholar.org/paper/378ef6735577260016f767bfd17c66c1f3892a9f\n",
      "\n",
      "   üìù Abstract: No abstract available...\n",
      "   ----------------------------------------------------------------------------\n",
      "\n",
      "9. BERT, RoBERTa or DeBERTa? Comparing Performance Across Transformer Models in Political Science Text\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Joan Carreras Timoneda, Sebasti√°n Vallejo Vera\n",
      "   üìÖ –î–∞—Ç–∞: 2024-04-03\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 24\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "   üîó URL: https://www.semanticscholar.org/paper/63a3787731efbdf2cdad958edccc1cb93b3c80c8\n",
      "\n",
      "   üìù Abstract: Transformer models such as BERT, RoBERTa, and DeBERTa have revolutionized the field of Natural Language Processing in recent years with substantial improvements in the contextual understanding of text...\n",
      "   ----------------------------------------------------------------------------\n",
      "\n",
      "10. Preference Transformer: Modeling Human Preferences using Transformers for RL\n",
      "   üë• –ê–≤—Ç–æ—Ä–∏: Changyeon Kim, Jongjin Park...\n",
      "   üìÖ –î–∞—Ç–∞: 2023-03-02\n",
      "   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: N/A\n",
      "   üìä –î–∂–µ—Ä–µ–ª–æ: arXiv\n",
      "   üîó URL: http://arxiv.org/abs/2303.00957v1\n",
      "   üìÑ PDF: https://arxiv.org/pdf/2303.00957v1\n",
      "\n",
      "   üìù Abstract: Preference-based reinforcement learning (RL) provides a framework to train agents using human preferences between two behaviors. However, preference-based RL has been challenging to scale since it req...\n",
      "   ----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"üèÜ –¢–æ–ø-10 –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à–∏—Ö —Å—Ç–∞—Ç–µ–π:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, paper in enumerate(ranked_papers, 1):\n",
    "    print(f\"\\n{i}. {paper.title}\")\n",
    "    print(f\"   üë• –ê–≤—Ç–æ—Ä–∏: {', '.join(paper.authors[:2])}{'...' if len(paper.authors) > 2 else ''}\")\n",
    "    print(f\"   üìÖ –î–∞—Ç–∞: {paper.published_date}\")\n",
    "    print(f\"   üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: {paper.citations_count if paper.citations_count else 'N/A'}\")\n",
    "    print(f\"   üìä –î–∂–µ—Ä–µ–ª–æ: {paper.source}\")\n",
    "    print(f\"   üîó URL: {paper.url}\")\n",
    "    if paper.pdf_url:\n",
    "        print(f\"   üìÑ PDF: {paper.pdf_url}\")\n",
    "    print(f\"\\n   üìù Abstract: {paper.abstract[:200]}...\")\n",
    "    print(\"   \" + \"-\" * 76)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a2937d",
   "metadata": {},
   "source": [
    "## 4. –¢–µ—Å—Ç 2: –Ü–Ω—à–∞ —Ç–µ–º–∞ - Attention Mechanisms\n",
    "\n",
    "–°–ø—Ä–æ–±—É—î–º–æ –∑ —ñ–Ω—à–æ—é —Ç–µ–º–æ—é:\n",
    "\n",
    "**‚ö†Ô∏è –ü—Ä–∏–º—ñ—Ç–∫–∞ –ø—Ä–æ Rate Limits:**\n",
    "- Semantic Scholar: 100 –∑–∞–ø–∏—Ç—ñ–≤ / 5 —Ö–≤–∏–ª–∏–Ω (–±–µ–∑ API –∫–ª—é—á–∞)\n",
    "- –Ø–∫—â–æ –±–∞—á–∏—à –ø–æ–º–∏–ª–∫—É 429 (\"Too Many Requests\") ‚Äî —Ü–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ!\n",
    "- –ö–æ–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø—Ä–æ–¥–æ–≤–∂–∏—Ç—å –∑ arXiv —ñ –Ω–µ –≤–ø–∞–¥–µ\n",
    "- –©–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ rate limits: –∑–º–µ–Ω—à `max_results_per_source` –∞–±–æ –∑–∞—á–µ–∫–∞–π 5 —Ö–≤–∏–ª–∏–Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4937e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –®—É–∫–∞—î–º–æ —Å—Ç–∞—Ç—Ç—ñ –∑–∞ –∑–∞–ø–∏—Ç–æ–º: 'attention mechanisms in neural networks'...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Semantic Scholar API error: 429 - {\"message\": \"Too Many Requests. Please wait and try again or apply for a key for higher rate limits. https://www.semanticscholar.org/product/api#api-key-form\", \"code\": \"429\"}\n",
      "Semantic Scholar API error: Client error '429 ' for url 'https://api.semanticscholar.org/graph/v1/paper/search?query=attention+mechanisms+in+neural+networks&limit=8&fields=paperId%2Ctitle%2Cabstract%2Cauthors%2Cyear%2CpublicationDate%2Curl%2CopenAccessPdf%2CcitationCount%2CfieldsOfStudy%2CexternalIds'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/veronika/paper-survey-agent/src/paper_survey_agent/tools/retrieval.py\", line 151, in _fetch_from_semantic_scholar\n",
      "    papers = await api.search(query, max_results=max_results)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/src/paper_survey_agent/apis/semantic_scholar.py\", line 127, in search\n",
      "    response.raise_for_status()\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/httpx/_models.py\", line 829, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '429 ' for url 'https://api.semanticscholar.org/graph/v1/paper/search?query=attention+mechanisms+in+neural+networks&limit=8&fields=paperId%2Ctitle%2Cabstract%2Cauthors%2Cyear%2CpublicationDate%2Curl%2CopenAccessPdf%2CcitationCount%2CfieldsOfStudy%2CexternalIds'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
      "Failed to fetch from semantic_scholar: Client error '429 ' for url 'https://api.semanticscholar.org/graph/v1/paper/search?query=attention+mechanisms+in+neural+networks&limit=8&fields=paperId%2Ctitle%2Cabstract%2Cauthors%2Cyear%2CpublicationDate%2Curl%2CopenAccessPdf%2CcitationCount%2CfieldsOfStudy%2CexternalIds'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/veronika/paper-survey-agent/src/paper_survey_agent/tools/retrieval.py\", line 151, in _fetch_from_semantic_scholar\n",
      "    papers = await api.search(query, max_results=max_results)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/src/paper_survey_agent/apis/semantic_scholar.py\", line 127, in search\n",
      "    response.raise_for_status()\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/httpx/_models.py\", line 829, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '429 ' for url 'https://api.semanticscholar.org/graph/v1/paper/search?query=attention+mechanisms+in+neural+networks&limit=8&fields=paperId%2Ctitle%2Cabstract%2Cauthors%2Cyear%2CpublicationDate%2Curl%2CopenAccessPdf%2CcitationCount%2CfieldsOfStudy%2CexternalIds'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
      "Semantic Scholar API error: Client error '429 ' for url 'https://api.semanticscholar.org/graph/v1/paper/search?query=attention+mechanisms+in+neural+networks&limit=8&fields=paperId%2Ctitle%2Cabstract%2Cauthors%2Cyear%2CpublicationDate%2Curl%2CopenAccessPdf%2CcitationCount%2CfieldsOfStudy%2CexternalIds'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/veronika/paper-survey-agent/src/paper_survey_agent/tools/retrieval.py\", line 151, in _fetch_from_semantic_scholar\n",
      "    papers = await api.search(query, max_results=max_results)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/src/paper_survey_agent/apis/semantic_scholar.py\", line 127, in search\n",
      "    response.raise_for_status()\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/httpx/_models.py\", line 829, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '429 ' for url 'https://api.semanticscholar.org/graph/v1/paper/search?query=attention+mechanisms+in+neural+networks&limit=8&fields=paperId%2Ctitle%2Cabstract%2Cauthors%2Cyear%2CpublicationDate%2Curl%2CopenAccessPdf%2CcitationCount%2CfieldsOfStudy%2CexternalIds'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
      "Failed to fetch from semantic_scholar: Client error '429 ' for url 'https://api.semanticscholar.org/graph/v1/paper/search?query=attention+mechanisms+in+neural+networks&limit=8&fields=paperId%2Ctitle%2Cabstract%2Cauthors%2Cyear%2CpublicationDate%2Curl%2CopenAccessPdf%2CcitationCount%2CfieldsOfStudy%2CexternalIds'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/veronika/paper-survey-agent/src/paper_survey_agent/tools/retrieval.py\", line 151, in _fetch_from_semantic_scholar\n",
      "    papers = await api.search(query, max_results=max_results)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"/home/veronika/paper-survey-agent/src/paper_survey_agent/apis/semantic_scholar.py\", line 127, in search\n",
      "    response.raise_for_status()\n",
      "  File \"/home/veronika/paper-survey-agent/.venv/lib/python3.10/site-packages/httpx/_models.py\", line 829, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '429 ' for url 'https://api.semanticscholar.org/graph/v1/paper/search?query=attention+mechanisms+in+neural+networks&limit=8&fields=paperId%2Ctitle%2Cabstract%2Cauthors%2Cyear%2CpublicationDate%2Curl%2CopenAccessPdf%2CcitationCount%2CfieldsOfStudy%2CexternalIds'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ 8 —Å—Ç–∞—Ç–µ–π\n",
      "\n",
      "üèÜ –¢–æ–ø-5 –ø—ñ—Å–ª—è —Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è:\n",
      "\n",
      "1. The Deep Arbitrary Polynomial Chaos Neural Network or how Deep Artificial Neural Networks could benefit from Data-Driven Homogeneous Chaos Theory\n",
      "   üìÖ 2023-06-26 | üìñ N/A —Ü–∏—Ç—É–≤–∞–Ω—å\n",
      "\n",
      "2. Hierarchical Attentional Hybrid Neural Networks for Document Classification\n",
      "   üìÖ 2019-01-20 | üìñ N/A —Ü–∏—Ç—É–≤–∞–Ω—å\n",
      "\n",
      "3. A Review on Neural Network Models of Schizophrenia and Autism Spectrum Disorder\n",
      "   üìÖ 2019-06-24 | üìñ N/A —Ü–∏—Ç—É–≤–∞–Ω—å\n",
      "\n",
      "4. Learning Active Subspaces and Discovering Important Features with Gaussian Radial Basis Functions Neural Networks\n",
      "   üìÖ 2023-07-11 | üìñ N/A —Ü–∏—Ç—É–≤–∞–Ω—å\n",
      "\n",
      "5. Continual Learning for Recurrent Neural Networks: an Empirical Evaluation\n",
      "   üìÖ 2021-03-12 | üìñ N/A —Ü–∏—Ç—É–≤–∞–Ω—å\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"attention mechanisms in neural networks\"\n",
    "print(f\"üîç –®—É–∫–∞—î–º–æ —Å—Ç–∞—Ç—Ç—ñ –∑–∞ –∑–∞–ø–∏—Ç–æ–º: '{query2}'...\\n\")\n",
    "\n",
    "papers2 = await retrieve_papers(\n",
    "    query=query2,\n",
    "    sources=[\"arxiv\", \"semantic_scholar\"],\n",
    "    max_results_per_source=8\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(papers2)} —Å—Ç–∞—Ç–µ–π\")\n",
    "\n",
    "# –†–∞–Ω–∂—É–≤–∞–Ω–Ω—è\n",
    "ranked_papers2 = rank_and_deduplicate(\n",
    "    papers=papers2,\n",
    "    topic=query2,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(f\"\\nüèÜ –¢–æ–ø-5 –ø—ñ—Å–ª—è —Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è:\\n\")\n",
    "for i, paper in enumerate(ranked_papers2, 1):\n",
    "    print(f\"{i}. {paper.title}\")\n",
    "    print(f\"   üìÖ {paper.published_date} | üìñ {paper.citations_count or 'N/A'} —Ü–∏—Ç—É–≤–∞–Ω—å\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f15c50",
   "metadata": {},
   "source": [
    "## 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "\n",
    "–ü–æ–¥–∏–≤–∏–º–æ—Å—å –∑–∞–≥–∞–ª—å–Ω—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90495f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π:\n",
      "\n",
      "–í—Å—å–æ–≥–æ –∑–Ω–∞–π–¥–µ–Ω–æ: 20\n",
      "–ü—ñ—Å–ª—è –¥–µ–¥—É–ø–ª—ñ–∫–∞—Ü—ñ—ó: 10\n",
      "–í–∏–¥–∞–ª–µ–Ω–æ –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤: 10\n",
      "\n",
      "–ü–æ –¥–∂–µ—Ä–µ–ª–∞–º:\n",
      "  - arXiv: 10\n",
      "  - Semantic Scholar: 10\n",
      "\n",
      "–ü–æ —Ä–æ–∫–∞–º –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó (—Ç–æ–ø-10):\n",
      "  - 2024: 6\n",
      "  - 2023: 2\n",
      "  - 2022: 2\n",
      "\n",
      "–°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ü–∏—Ç—É–≤–∞–Ω—å: 802.4\n",
      "–ú–∞–∫—Å. —Ü–∏—Ç—É–≤–∞–Ω—å: 4302\n",
      "–ú—ñ–Ω. —Ü–∏—Ç—É–≤–∞–Ω—å: 24\n",
      "\n",
      "–°—Ç–∞—Ç–µ–π –∑ PDF: 5/10 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π:\\n\")\n",
    "print(f\"–í—Å—å–æ–≥–æ –∑–Ω–∞–π–¥–µ–Ω–æ: {len(papers)}\")\n",
    "print(f\"–ü—ñ—Å–ª—è –¥–µ–¥—É–ø–ª—ñ–∫–∞—Ü—ñ—ó: {len(ranked_papers)}\")\n",
    "print(f\"–í–∏–¥–∞–ª–µ–Ω–æ –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤: {len(papers) - len(ranked_papers)}\")\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∂–µ—Ä–µ–ª–∞–º\n",
    "sources = Counter(p.source for p in papers)\n",
    "print(f\"\\n–ü–æ –¥–∂–µ—Ä–µ–ª–∞–º:\")\n",
    "for source, count in sources.items():\n",
    "    print(f\"  - {source}: {count}\")\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–æ–∫–∞–º\n",
    "years = [p.published_date.year for p in ranked_papers]\n",
    "year_counts = Counter(years)\n",
    "print(f\"\\n–ü–æ —Ä–æ–∫–∞–º –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó (—Ç–æ–ø-10):\")\n",
    "for year, count in sorted(year_counts.items(), reverse=True):\n",
    "    print(f\"  - {year}: {count}\")\n",
    "\n",
    "# –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ü–∏—Ç—É–≤–∞–Ω—å\n",
    "citations = [p.citations_count for p in ranked_papers if p.citations_count]\n",
    "if citations:\n",
    "    avg_citations = sum(citations) / len(citations)\n",
    "    print(f\"\\n–°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ü–∏—Ç—É–≤–∞–Ω—å: {avg_citations:.1f}\")\n",
    "    print(f\"–ú–∞–∫—Å. —Ü–∏—Ç—É–≤–∞–Ω—å: {max(citations)}\")\n",
    "    print(f\"–ú—ñ–Ω. —Ü–∏—Ç—É–≤–∞–Ω—å: {min(citations)}\")\n",
    "\n",
    "# –ù–∞—è–≤–Ω—ñ—Å—Ç—å PDF\n",
    "with_pdf = sum(1 for p in ranked_papers if p.pdf_url)\n",
    "print(f\"\\n–°—Ç–∞—Ç–µ–π –∑ PDF: {with_pdf}/{len(ranked_papers)} ({with_pdf/len(ranked_papers)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443019d1",
   "metadata": {},
   "source": [
    "## 6. –¢–µ—Å—Ç —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–æ—ó —Å—Ç–∞—Ç—Ç—ñ\n",
    "\n",
    "–ü–µ—Ä–µ–≤—ñ—Ä–∏–º–æ –¥–µ—Ç–∞–ª—ñ –æ–¥–Ω—ñ—î—ó —Å—Ç–∞—Ç—Ç—ñ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6229f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à—É —Å—Ç–∞—Ç—Ç—é:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìÑ –ù–∞–∑–≤–∞: GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints\n",
      "\n",
      "üë• –ê–≤—Ç–æ—Ä–∏: J. Ainslie, J. Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebr'on, Sumit K. Sanghai\n",
      "\n",
      "üìÖ –î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó: 2023-05-22\n",
      "üìä –î–∂–µ—Ä–µ–ª–æ: Semantic Scholar\n",
      "üÜî ID: arxiv:2305.13245\n",
      "üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: 1055\n",
      "üîó URL: https://www.semanticscholar.org/paper/5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200\n",
      "üìÑ PDF: http://arxiv.org/pdf/2305.13245\n",
      "üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä—ñ—ó: Computer Science\n",
      "\n",
      "üìù Abstract:\n",
      "Multi-query attention (MQA), which only uses a single key-value head, drastically speeds up decoder inference. However, MQA can lead to quality degradation, and moreover it may not be desirable to train a separate model just for faster inference. We (1) propose a recipe for uptraining existing multi-head language model checkpoints into models with MQA using 5% of original pre-training compute, and (2) introduce grouped-query attention (GQA), a generalization of multi-query attention which uses an intermediate (more than one, less than number of query heads) number of key-value heads. We show that uptrained GQA achieves quality close to multi-head attention with comparable speed to MQA.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# –í—ñ–∑—å–º–µ–º–æ –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à—É —Å—Ç–∞—Ç—Ç—é\n",
    "top_paper = ranked_papers[0]\n",
    "\n",
    "print(\"üîç –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à—É —Å—Ç–∞—Ç—Ç—é:\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìÑ –ù–∞–∑–≤–∞: {top_paper.title}\\n\")\n",
    "print(f\"üë• –ê–≤—Ç–æ—Ä–∏: {', '.join(top_paper.authors)}\\n\")\n",
    "print(f\"üìÖ –î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó: {top_paper.published_date}\")\n",
    "print(f\"üìä –î–∂–µ—Ä–µ–ª–æ: {top_paper.source}\")\n",
    "print(f\"üÜî ID: {top_paper.id}\")\n",
    "print(f\"üìñ –¶–∏—Ç—É–≤–∞–Ω–Ω—è: {top_paper.citations_count if top_paper.citations_count else 'N/A'}\")\n",
    "print(f\"üîó URL: {top_paper.url}\")\n",
    "if top_paper.pdf_url:\n",
    "    print(f\"üìÑ PDF: {top_paper.pdf_url}\")\n",
    "print(f\"üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä—ñ—ó: {', '.join(top_paper.categories) if top_paper.categories else 'N/A'}\")\n",
    "print(f\"\\nüìù Abstract:\\n{top_paper.abstract}\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2f62e",
   "metadata": {},
   "source": [
    "## ‚úÖ –í–∏—Å–Ω–æ–≤–æ–∫\n",
    "\n",
    "–í—Å—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –ø—Ä–∞—Ü—é—é—Ç—å:\n",
    "- ‚úÖ –ü–æ—à—É–∫ –∑ arXiv API\n",
    "- ‚úÖ –ü–æ—à—É–∫ –∑ Semantic Scholar API\n",
    "- ‚úÖ –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π –≤–∏–∫–ª–∏–∫ –æ–±–æ—Ö API\n",
    "- ‚úÖ **Graceful degradation** ‚Äî —è–∫—â–æ –æ–¥–∏–Ω API –ø–∞–¥–∞—î (rate limit), –∫–æ–¥ –ø—Ä–æ–¥–æ–≤–∂—É—î –∑ —ñ–Ω—à–∏–º\n",
    "- ‚úÖ –î–µ–¥—É–ø–ª—ñ–∫–∞—Ü—ñ—è –∑–∞ ID —Ç–∞ fuzzy matching\n",
    "- ‚úÖ –†–∞–Ω–∂—É–≤–∞–Ω–Ω—è –∑–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—é, —Ü–∏—Ç—É–≤–∞–Ω–Ω—è–º–∏ —Ç–∞ –¥–∞—Ç–æ—é\n",
    "- ‚úÖ –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤\n",
    "\n",
    "---\n",
    "\n",
    "### üìù –ü—Ä–æ Rate Limits:\n",
    "\n",
    "**Semantic Scholar:**\n",
    "- –ë–µ–∑ API –∫–ª—é—á–∞: **100 –∑–∞–ø–∏—Ç—ñ–≤ / 5 —Ö–≤–∏–ª–∏–Ω**\n",
    "- –ó API –∫–ª—é—á–µ–º: **5000 –∑–∞–ø–∏—Ç—ñ–≤ / 5 —Ö–≤–∏–ª–∏–Ω** üöÄ\n",
    "\n",
    "**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:**\n",
    "1. –î–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –º–µ–Ω—à–µ –∑–∞–ø–∏—Ç—ñ–≤ (`max_results_per_source=5`)\n",
    "2. –ê–±–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Ç—ñ–ª—å–∫–∏ arXiv: `sources=[\"arxiv\"]`\n",
    "3. –ê–±–æ –∑–∞—á–µ–∫–∞–π 5 —Ö–≤–∏–ª–∏–Ω –º—ñ–∂ —Ç–µ—Å—Ç–∞–º–∏\n",
    "4. –î–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω—É ‚Äî –æ—Ç—Ä–∏–º–∞–π API –∫–ª—é—á: https://www.semanticscholar.org/product/api#api-key-form\n",
    "\n",
    "---\n",
    "\n",
    "**–ì–æ—Ç–æ–≤–æ –¥–ª—è —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó –∑ LLM!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
